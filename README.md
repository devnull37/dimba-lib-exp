# DIMBA ğŸâœ¨

[![PyPI version](https://badge.fury.io/py/dimba-lib.svg)](https://badge.fury.io/py/dimba-lib)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

> **Diffusion-based Mamba Architecture for Non-Autoregressive Text Generation**

DIMBA is a research-grade language model that combines the power of diffusion models with Mamba-2 State Space Models (SSM) to enable **fast, parallel text generation**. Unlike traditional autoregressive models that generate tokens one-by-one, DIMBA generates entire sequences simultaneously through iterative denoising.

ğŸ”¬ **Research Paper**: *"DIMBA: Revolutionizing Theoretical Ultra-Fast Inference and Advanced Reasoning with Mamba-Based Diffusion"* â€” Faris Allafi (2025)

ğŸŒ **Website**: [dimbalabs.xyz](https://dimbalabs.xyz)  
ğŸ‘¤ **Author**: [farisallafi.xyz](https://farisallafi.xyz)

---

## ğŸš€ Key Features

### âš¡ Pure PyTorch Mamba-2 Implementation
- **No CUDA dependencies required** â€” runs on CPU, GPU, and Apple Silicon
- Custom `SimpleMamba2` fallback implementation when `mamba-ssm` is unavailable
- Seamlessly switches between high-performance CUDA kernels and pure PyTorch

### ğŸ¯ Latent Space Diffusion with VAE
- Optional Variational Autoencoder for compressing token embeddings
- Trainable latent spaces with KL-regularization (Î²-VAE)
- Improves diffusion efficiency and model capacity

### ğŸ Native Apple Silicon (MPS) Support
- First-class Metal Performance Shaders support
- Optimized for M1/M2/M3 Macs without CUDA

### ğŸ® Interactive Training Scripts
- `train_interactive.py` â€” guided wizard for easy configuration
- Automatic hardware detection and optimization recommendations
- One-command training for various GPU tiers (A4000, L40S, etc.)

### ğŸ”§ Multiple Decoding Strategies
- **Standard diffusion sampling** â€” flexible step counts
- **DDIM sampling** â€” faster inference with fewer steps
- **Consistency training** (CDLM) â€” up to 14Ã— faster inference
- Top-k, top-p, and temperature-based sampling

---

## ğŸ“ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DIMBA Architecture                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input Tokens                                               â”‚
â”‚       â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Token     â”‚â”€â”€â”€â†’â”‚   Prompt    â”‚â”€â”€â”€â†’â”‚  Conditioning   â”‚ â”‚
â”‚  â”‚ Embeddings  â”‚    â”‚  Encoder    â”‚    â”‚      (C)        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â†“                                      â†“              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Latent Projection (Optional VAE)          â”‚   â”‚
â”‚  â”‚     z = Î¼ + ÏƒÂ·Îµ  (reparameterization trick)         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Cosine Noise Schedule                   â”‚   â”‚
â”‚  â”‚     á¾±(t) = cosÂ²((t/T + s)/(1+s)Â·Ï€/2)               â”‚   â”‚
â”‚  â”‚     x_t = âˆšá¾±(t)Â·xâ‚€ + âˆš(1-á¾±(t))Â·Îµ                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Mamba-2 Denoiser (T iterations)             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  Mamba-2 SSM Block Ã— N layers              â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - Linear-time sequence processing         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - Selective state spaces (S6)             â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - FiLM/Additive conditioning              â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Output    â”‚â”€â”€â”€â†’â”‚   Latent    â”‚â”€â”€â”€â†’â”‚  Token Logits   â”‚ â”‚
â”‚  â”‚ Projection  â”‚    â”‚    Decode   â”‚    â”‚   (Softmax)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                  â†“          â”‚
â”‚                                          Generated Text     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

| Component | Description |
|-----------|-------------|
| **Token Embeddings** | Learnable embeddings mapping discrete tokens to continuous space |
| **Prompt Encoder** | Lightweight MLP for conditioning on prefix tokens |
| **Noise Schedule** | Cosine schedule following Nichol & Dhariwal (2021) |
| **Timestep Embeddings** | Sinusoidal encodings with MLP projection |
| **Mamba-2 Denoiser** | Stack of SSM blocks with FiLM/additive conditioning |
| **VAE (Optional)** | Token-level variational autoencoder for latent diffusion |

---

## ğŸš€ Getting Started

### Installation

```bash
# Clone the repository
git clone https://github.com/devnull37/dimba-lib-exp.git
cd dimba-lib-exp

# Basic installation (CPU + SimpleMamba fallback)
pip install -e .

# With GPU support (full Mamba-2 with CUDA)
pip install -e ".[gpu]"

# Full development setup (includes all extras)
pip install -e ".[all]"
```

### Quick Start

#### Option 1: Interactive Setup (Recommended)

```bash
# Launch the interactive training wizard
python scripts/train_interactive.py
```

The wizard will guide you through:
- Hardware detection (CUDA, MPS, or CPU)
- Model size selection
- Dataset configuration
- Training hyperparameters

#### Option 2: Command-Line Training

```bash
# Train on GPU
python scripts/train.py --config config.yaml --gpus 1 --max-epochs 10

# Train on CPU (uses SimpleMamba)
python scripts/train.py --config config.yaml

# Train on Apple Silicon
python scripts/train.py --config config.yaml --mps
```

#### Option 3: Python API

```python
import torch
from dimba import DIMBA, sample_from_model

# Create a DIMBA model
model = DIMBA(
    vocab_size=50000,
    d_model=512,
    num_diffusion_steps=1000,
    num_denoiser_layers=8,
)

# Generate text
prompt_ids = torch.tensor([[10, 20, 30]])  # Tokenized prompt
generated = sample_from_model(
    model, 
    prompt_ids, 
    seq_len=100, 
    num_steps=50,  # Fewer steps = faster, more steps = better quality
    temperature=1.0,
    top_p=0.95
)

print(generated)
```

---

## ğŸ–¥ï¸ Hardware Support

| Platform | Status | Notes |
|----------|--------|-------|
| **NVIDIA CUDA** | âœ… Full support | Best performance with `mamba-ssm>=2.2.0` |
| **Apple Silicon (MPS)** | âœ… Full support | Native Metal backend for M1/M2/M3 |
| **CPU** | âœ… Supported | Uses pure PyTorch `SimpleMamba2` fallback |
| **AMD ROCm** | âš ï¸ Experimental | Via PyTorch ROCm builds |

### Hardware-Specific Training Scripts

```bash
# RTX A4000 (16GB VRAM) - 500M parameter model
python scripts/train_fineweb_500m_a4000.py

# L40S / A100 - 1.5B parameter model  
python scripts/train_fineweb_1b.py

# CDLM (Consistency Training) - up to 14Ã— faster inference
python scripts/train_cdlm.py
```

---

## ğŸ§ª Advanced Features

### VAE Pre-training for Latent Diffusion

Pre-train a Variational Autoencoder to compress token embeddings:

```bash
# Basic VAE training
python scripts/train_vae.py \
    --dataset wikitext \
    --dataset-config wikitext-2-raw-v1 \
    --latent-dim 256 \
    --kl-weight 1.0 \
    --epochs 10
```

Use the pre-trained VAE in DIMBA:

```python
model = DIMBA(
    vocab_size=50000,
    d_model=512,
    latent_diffusion=True,
    d_latent=256,
    use_vae_latent=True,
    vae_checkpoint_path='checkpoints/vae/final.ckpt',
)
```

### Consistency Training (CDLM)

Train with Consistency Models for ultra-fast inference:

```bash
python scripts/train_cdlm.py \
    --config config.yaml \
    --consistency-weight 0.5 \
    --delta-min 50 \
    --delta-max 200
```

---

## ğŸ“Š Project Status

### âœ… What's Working

- [x] Core diffusion training pipeline
- [x] Mamba-2 denoiser with FiLM conditioning
- [x] Pure PyTorch SimpleMamba2 fallback
- [x] VAE-based latent diffusion
- [x] DDIM sampling for faster inference
- [x] Interactive training wizard
- [x] Multi-GPU training (PyTorch Lightning)
- [x] Apple Silicon (MPS) support
- [x] HuggingFace datasets integration
- [x] BPE tokenization
- [x] EMA (Exponential Moving Average) training
- [x] Checkpointing and resumption

### ğŸš§ Experimental / In Progress

- [ ] Consistency model training (CDLM)
- [ ] Multi-modal extensions
- [ ] Quantization support (INT8, INT4)
- [ ] ONNX export
- [ ] Flash Attention integration
- [ ] Rotary Position Embeddings (RoPE)

### âš ï¸ Known Limitations

1. **Training cost**: Diffusion models require substantial compute for pre-training
2. **Discrete-continuous gap**: Mapping between discrete tokens and continuous embeddings affects rare token handling
3. **Hyperparameter sensitivity**: Performance varies significantly with diffusion steps (T), architecture depth
4. **Conditioning robustness**: Long-context conditioning requires careful tuning

---

## ğŸ“ Project Structure

```
dimba-lib-exp/
â”œâ”€â”€ src/dimba/                 # Core library
â”‚   â”œâ”€â”€ models/               # Model implementations
â”‚   â”‚   â”œâ”€â”€ diffusion.py      # Main DIMBA model
â”‚   â”‚   â”œâ”€â”€ denoiser.py       # Mamba-2 denoiser
â”‚   â”‚   â”œâ”€â”€ vae.py            # Token VAE
â”‚   â”‚   â”œâ”€â”€ embeddings.py     # Embedding layers
â”‚   â”‚   â””â”€â”€ simple_mamba.py   # Pure PyTorch Mamba
â”‚   â”œâ”€â”€ diffusion/            # Diffusion utilities
â”‚   â”‚   â”œâ”€â”€ schedules.py      # Noise schedules
â”‚   â”‚   â””â”€â”€ sampling.py       # Sampling algorithms
â”‚   â”œâ”€â”€ data/                 # Dataset loaders
â”‚   â”œâ”€â”€ training/             # Training utilities
â”‚   â”œâ”€â”€ evaluation/           # Metrics (BLEU, ROUGE, etc.)
â”‚   â””â”€â”€ tokenizers/           # Tokenization
â”œâ”€â”€ scripts/                  # Training & utility scripts
â”‚   â”œâ”€â”€ train_interactive.py  # Interactive wizard â­
â”‚   â”œâ”€â”€ train.py              # Generic training
â”‚   â”œâ”€â”€ train_vae.py          # VAE pre-training
â”‚   â”œâ”€â”€ train_cdlm.py         # Consistency training
â”‚   â”œâ”€â”€ generate.py           # Text generation
â”‚   â”œâ”€â”€ evaluate.py           # Evaluation
â”‚   â””â”€â”€ setup/                # Installation scripts
â”œâ”€â”€ configs/                  # Configuration files
â”œâ”€â”€ tests/                    # Unit tests
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â”œâ”€â”€ paper/                    # Research paper
â””â”€â”€ docs/                     # Documentation
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Install** development dependencies: `pip install -e ".[dev]"`
4. **Make** your changes
5. **Run** tests: `pytest`
6. **Format** code: `black src/ && isort src/`
7. **Submit** a Pull Request

### Development Setup

```bash
pip install -e ".[all]"
pre-commit install  # Optional: for automated formatting
```

---

## ğŸ“– Citation

If you use DIMBA in your research, please cite:

```bibtex
@article{allafi2025dimba,
  title={DIMBA: Revolutionizing Theoretical Ultra-Fast Inference and Advanced Reasoning with Mamba-Based Diffusion},
  author={Allafi, Faris},
  year={2025}
}
```

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ”— Links

- ğŸŒ **Website**: [dimbalabs.xyz](https://dimbalabs.xyz)
- ğŸ‘¤ **Author**: [farisallafi.xyz](https://farisallafi.xyz)
- ğŸ“„ **Paper**: Available in the `paper/` directory
- ğŸ’» **Repository**: [github.com/devnull37/dimba-lib-exp](https://github.com/devnull37/dimba-lib-exp)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/devnull37/dimba-lib-exp/issues)

---

## ğŸ’¡ Acknowledgments

- **Mamba** â€” [State Space Models](https://github.com/state-spaces/mamba) by Tri Dao and Albert Gu
- **Diffusion Models** â€” Inspired by works from OpenAI, Google Research, and the broader diffusion community
- **PyTorch Lightning** â€” For the excellent training framework
- **HuggingFace** â€” For datasets and transformers infrastructure

---

<p align="center">
  <i>Built with â¤ï¸ by Faris Allafi</i>
</p>
